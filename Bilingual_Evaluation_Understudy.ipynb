{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_text = \"Congress may not make any laws to establish religion, to ban free religious practice, to impede freedom of speech, or to restrict the freedom of the press, the right to peaceful assembly, or the right to petition the government.\"\n",
    "ref_text = \"Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the Government for a redress of grievances.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "trans_tokenized = tokenizer.tokenize(trans_text)\n",
    "ref_tokenized = tokenizer.tokenize(ref_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "#1-grams\n",
    "mw = len(set([x for x in trans_tokenized if x in ref_tokenized]))\n",
    "wt = len(trans_tokenized)\n",
    "Pn = mw/wt\n",
    "print(Pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BLEU(trans_tokenized, ref_tokenized, n):\n",
    "    trans_ngrams = list(ngrams(trans_tokenized, n))\n",
    "    ref_ngrams = list(ngrams(ref_tokenized, n))\n",
    "    mw = len(set([x for x in trans_ngrams if x in ref_ngrams]))\n",
    "    wt = len(trans_ngrams)\n",
    "    Pn = mw/wt\n",
    "    return Pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2631578947368421"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2-grams\n",
    "get_BLEU(trans_tokenized, ref_tokenized, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16216216216216217"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3-grams\n",
    "get_BLEU(trans_tokenized, ref_tokenized, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027777777777777776"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4-grams\n",
    "get_BLEU(trans_tokenized, ref_tokenized, 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
